{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generic-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "from utils.inference.image_processing import crop_face\n",
    "from utils.inference.video_processing import read_video, get_final_video_frame, add_audio_from_another_video, face_enhancement, get_final_video_multi\n",
    "from utils.inference.core import model_inference, model_inference_multi\n",
    "\n",
    "from network.AEI_Net import AEI_Net\n",
    "from coordinate_reg.image_infer import Handler\n",
    "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
    "from arcface_model.iresnet import iresnet100\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.config_sr import TestOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-logan",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "analyzed-butterfly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n",
      "loading ./coordinate_reg/model/2d106det 0\n",
      "input mean and std: 127.5 127.5\n",
      "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
      "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
    "\n",
    "# main model for generation\n",
    "G = AEI_Net(c_id=512)\n",
    "G.eval()\n",
    "G.load_state_dict(torch.load('weights/G_0_035000_init_arch_arcface2.pth', map_location=torch.device('cpu')))\n",
    "G = G.cuda()\n",
    "G = G.half()\n",
    "\n",
    "# arcface model to get face embedding\n",
    "netArc = iresnet100(fp16=False)\n",
    "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
    "netArc=netArc.cuda()\n",
    "netArc.eval()\n",
    "\n",
    "# model to get face landmarks\n",
    "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
    "\n",
    "# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n",
    "use_sr = False\n",
    "if use_sr:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    opt = TestOptions()\n",
    "    #opt.which_epoch ='10_7'\n",
    "    model = Pix2PixModel(opt)\n",
    "    model.netG.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-removal",
   "metadata": {},
   "source": [
    "### Set here path to source image and video for faceswap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recognized-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "choose not really long videos, coz it can take a lot of time othervise \n",
    "choose source image as a photo -- preferable a selfie of a person\n",
    "\"\"\"\n",
    "\n",
    "path_to_video = 'examples/videos/video5_mod.mp4'\n",
    "source_full = cv2.imread('examples/images/elon_musk.jpg')\n",
    "OUT_VIDEO_NAME = \"examples/results/testing_multi.mp4\"\n",
    "crop_size = 224 # don't change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "featured-toolbox",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# check, if we can detect face on the source image\n",
    "\n",
    "source_images = [source_full]\n",
    "\n",
    "source = []\n",
    "try:\n",
    "    for source_image in source_images:     \n",
    "        source.append(crop_face(source_image, app, crop_size)[0])\n",
    "except TypeError:\n",
    "    print(\"Bad source images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cordless-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# read video\n",
    "\n",
    "full_frames, fps = read_video(path_to_video)\n",
    "\n",
    "target1 = full_frames[0]\n",
    "target_images = [target1]\n",
    "\n",
    "target = []\n",
    "try:\n",
    "    for target_image in target_images: \n",
    "        target.append(crop_face(target_image, app, crop_size)[0])\n",
    "except TypeError:\n",
    "    print(\"Bad target images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-suggestion",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "solved-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "START_TIME = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cheap-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|██████████| 379/379 [01:21<00:00,  4.64it/s]\n",
      "379it [00:00, 4706.65it/s]\n",
      "100%|██████████| 7/7 [00:01<00:00,  3.78it/s]\n",
      "100%|██████████| 379/379 [00:00<00:00, 977639.12it/s]\n"
     ]
    }
   ],
   "source": [
    "final_frames_list, crop_frames_list, full_frames, tfm_array_list = model_inference_multi(full_frames,\n",
    "                                                                    source,\n",
    "                                                                    target,\n",
    "                                                                    netArc,\n",
    "                                                                    G,\n",
    "                                                                    app, \n",
    "                                                                    crop_size=crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "certified-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# final_frames, crop_frames, full_frames, tfm_array = model_inference(full_frames,\n",
    "#                                                                     source,\n",
    "#                                                                     [netArc],\n",
    "#                                                                     G,\n",
    "#                                                                     app, \n",
    "#                                                                     crop_size=crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "palestinian-spirit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# if use_sr:\n",
    "#     final_frames = face_enhancement(final_frames, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "interested-naples",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "  0%|          | 0/379 [00:00<?, ?it/s]/home/jovyan/conda/envs/faceshift_env/lib/python3.8/site-packages/kornia/geometry/transform/imgwarp.py:184: UserWarning: The align_corners default value has been changed. By default now is set True in order to match cv2.warpAffine. In case you want to keep your previous behaviour set it to False. This warning will disappear in kornia > v0.6.\n",
      "  warnings.warn(message)\n",
      "/home/jovyan/Nastya/sber-swap/utils/inference/video_processing.py:294: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  final = (mask_t*swap_t + (1-mask_t)*full_frame).type(torch.uint8).squeeze().permute(1,2,0).cpu().detach().numpy()\n",
      "100%|██████████| 379/379 [00:07<00:00, 52.82it/s]\n"
     ]
    }
   ],
   "source": [
    "get_final_video_multi(final_frames_list,\n",
    "                      crop_frames_list,\n",
    "                      full_frames,\n",
    "                      tfm_array_list,\n",
    "                      OUT_VIDEO_NAME,\n",
    "                      fps, \n",
    "                      handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promotional-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# get_final_video_frame(final_frames,\n",
    "#                       crop_frames,\n",
    "#                       full_frames,\n",
    "#                       tfm_array,\n",
    "#                       OUT_VIDEO_NAME,\n",
    "#                       fps, \n",
    "#                       handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "informative-railway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "add_audio_from_another_video(path_to_video, OUT_VIDEO_NAME, \"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "suited-politics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full pipeline took 94.33891129493713\n",
      "Video saved with path examples/results/testing_multi.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(f'Full pipeline took {time.time() - START_TIME}')\n",
    "print(f\"Video saved with path {OUT_VIDEO_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-funeral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facesh",
   "language": "python",
   "name": "facesh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
